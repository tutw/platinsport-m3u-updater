import requests
import xml.etree.ElementTree as ET
import re
from datetime import datetime, timedelta
import time
import random
import logging
from urllib.parse import urljoin, urlparse, quote, unquote
import concurrent.futures
from bs4 import BeautifulSoup
import urllib3
from pathlib import Path
import threading
import json
import pytz

# Disable SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

class LiveTVRealStreamExtractor:
    def __init__(self):
        self.session = requests.Session()
        self.session.verify = False
        self.base_url = "https://livetv.sx"
        self.reference_xml_url = "https://raw.githubusercontent.com/tutw/platinsport-m3u-updater/refs/heads/main/eventos_livetv_sx.xml"
        
        # ğŸ“… DETECCIÃ“N AUTOMÃTICA DEL DÃA ACTUAL (HORARIO ESPAÃ‘A)
        spain_tz = pytz.timezone('Europe/Madrid')
        self.current_date_spain = datetime.now(spain_tz).strftime('%-d de %B').lower()
        # Convertir mes al espaÃ±ol
        meses = {
            'january': 'enero', 'february': 'febrero', 'march': 'marzo',
            'april': 'abril', 'may': 'mayo', 'june': 'junio',
            'july': 'julio', 'august': 'agosto', 'september': 'septiembre',
            'october': 'octubre', 'november': 'noviembre', 'december': 'diciembre'
        }
        for en, es in meses.items():
            self.current_date_spain = self.current_date_spain.replace(en, es)
        
        logger.info(f"ğŸ‡ªğŸ‡¸ Fecha actual EspaÃ±a: {self.current_date_spain}")
        
        self.stats = {
            'events_processed': 0,
            'streams_found': 0,
            'failed_events': 0,
            'real_iframes_found': 0,
            'fake_iframes_skipped': 0
        }
        
        # ğŸ¯ PATRONES REALES BASADOS EN MI ANÃLISIS DE LIVETV.SX
        self.real_iframe_patterns = [
            # Patrones encontrados en mi anÃ¡lisis
            r'<iframe[^>]+src=["\']([^"\']*webplayer2?\.php[^"\']*)["\'][^>]*>',
            r'<iframe[^>]+src=["\']([^"\']*export/webplayer\.iframe\.php[^"\']*)["\'][^>]*>',
            r'<iframe[^>]+src=["\']([^"\']*gowm\.php[^"\']*)["\'][^>]*>',
            
            # Patrones para enlaces directos a reproductores
            r'href=["\']([^"\']*webplayer2?\.php\?[^"\']*t=(?:youtube|alieztv|ifr)[^"\']*)["\']',
            r'href=["\']([^"\']*export/webplayer\.iframe\.php\?[^"\']*)["\']',
            
            # Patrones para datos en JavaScript (conservativo)
            r'["\']([^"\']*webplayer2?\.php\?[^"\']*eid=\d+[^"\']*)["\']',
            r'["\']([^"\']*export/webplayer\.iframe\.php\?[^"\']*eid=\d+[^"\']*)["\']',
        ]
        
        # ğŸ”§ USER AGENTS ROTACIÃ“N
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        ]
        
        self.lock = threading.Lock()

    def get_dynamic_headers(self, referer=None):
        """Genera headers dinÃ¡micos para evitar detecciÃ³n"""
        headers = {
            'User-Agent': random.choice(self.user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'no-cache',
        }
        if referer:
            headers['Referer'] = referer
        return headers

    def robust_request(self, url, timeout=15, max_retries=2):
        """PeticiÃ³n HTTP robusta con reintentos"""
        for attempt in range(max_retries):
            try:
                headers = self.get_dynamic_headers()
                response = self.session.get(url, headers=headers, timeout=timeout, allow_redirects=True)
                
                if response.status_code == 200:
                    return response
                elif response.status_code in [429, 503, 502]:
                    wait_time = min(2 ** attempt + random.uniform(1, 3), 30)
                    logger.warning(f"Rate limit/Service error, waiting {wait_time:.1f}s...")
                    time.sleep(wait_time)
                elif response.status_code == 404:
                    logger.debug(f"URL not found: {url[:60]}...")
                    return None
                else:
                    logger.warning(f"Status {response.status_code} for {url[:60]}...")
                    
            except requests.exceptions.Timeout:
                logger.debug(f"Timeout on attempt {attempt + 1} for {url[:60]}...")
            except requests.exceptions.RequestException as e:
                logger.debug(f"Request failed in attempt {attempt + 1}: {str(e)[:80]}")
                
            if attempt < max_retries - 1:
                time.sleep(random.uniform(1, 2))
        
        return None

    def load_reference_events(self):
        """Carga eventos de referencia desde XML"""
        logger.info("ğŸ“¥ Descargando eventos de referencia desde XML...")
        response = self.robust_request(self.reference_xml_url)
        if not response:
            logger.error("âŒ Error al descargar el XML de referencia")
            return []
        
        try:
            root = ET.fromstring(response.content)
            events = []
            
            for evento_elem in root.findall('evento'):
                event_data = {}
                
                for child in evento_elem:
                    if child.text:
                        event_data[child.tag] = child.text.strip()
                
                # ğŸ¯ FILTRAR SOLO POR EL DÃA ACTUAL EN HORARIO ESPAÃ‘A
                if event_data.get('fecha') == self.current_date_spain and event_data.get('url'):
                    event_data['id'] = self.extract_event_id(event_data['url'])
                    event_data['datetime_iso'] = self.create_datetime_iso(
                        event_data.get('fecha'), event_data.get('hora')
                    )
                    event_data['cerca_hora_actual'] = self.is_near_current_time(
                        event_data.get('hora')
                    )
                    events.append(event_data)
            
            logger.info(f"ğŸ“Š Cargados {len(events)} eventos para {self.current_date_spain}")
            return events
            
        except ET.ParseError as e:
            logger.error(f"âŒ Error al parsear XML: {e}")
            return []

    def extract_event_id(self, url):
        """Extrae ID del evento desde URL"""
        if not url:
            return str(random.randint(100000000, 999999999))
        
        patterns = [
            r'/eventinfo/(\d+)_',
            r'eventinfo/(\d+)_',
            r'eventinfo/(\d+)',
            r'id=(\d+)',
            r'/(\d+)_'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        return str(abs(hash(url)) % 100000000)

    def create_datetime_iso(self, fecha, hora):
        """Crea datetime ISO desde fecha y hora"""
        try:
            if not hora:
                return f"2025-06-16T00:00:00"
            
            hora_clean = re.sub(r'[^\d:]', '', hora)
            if ':' in hora_clean and len(hora_clean.split(':')) >= 2:
                return f"2025-06-16T{hora_clean}:00"
            else:
                return f"2025-06-16T{hora_clean}:00:00"
        except:
            return "2025-06-16T00:00:00"

    def is_near_current_time(self, hora):
        """Verifica si el evento estÃ¡ cerca de la hora actual"""
        try:
            if not hora:
                return "False"
            
            hora_clean = re.sub(r'[^\d:]', '', hora)
            if ':' not in hora_clean:
                return "False"
            
            # Usar hora de EspaÃ±a
            spain_tz = pytz.timezone('Europe/Madrid')
            current_hour = datetime.now(spain_tz).hour
            event_hour = int(hora_clean.split(':')[0])
            
            return "True" if abs(event_hour - current_hour) <= 2 else "False"
        except:
            return "False"

    def extract_real_streams_only(self, event_url, event_name):
        """ğŸ¯ EXTRACTOR DE STREAMS REALES ÃšNICAMENTE"""
        logger.info(f"ğŸ” Analizando streams reales para: {event_name[:40]}...")
        real_streams = set()
        
        response = self.robust_request(event_url)
        if not response:
            logger.warning(f"âŒ No se pudo acceder a: {event_url}")
            return []

        content = response.text
        soup = BeautifulSoup(content, 'html.parser')

        # ğŸ¯ APLICAR PATRONES REALES SOLAMENTE
        for pattern in self.real_iframe_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
            for match in matches:
                normalized = self.normalize_url(match, event_url)
                if normalized and self.is_real_stream_url(normalized):
                    real_streams.add(normalized)
                    with self.lock:
                        self.stats['real_iframes_found'] += 1

        # ğŸ”— BUSCAR ENLACES DIRECTOS EN ELEMENTOS HTML
        for link in soup.find_all('a', href=True):
            href = link.get('href')
            if href and self.is_real_stream_url(href):
                normalized = self.normalize_url(href, event_url)
                if normalized:
                    real_streams.add(normalized)
                    with self.lock:
                        self.stats['real_iframes_found'] += 1

        # ğŸ“Š CONVERTIR A LISTA CON METADATOS
        stream_list = []
        for url in real_streams:
            stream_data = {
                'url': url,
                'type': self.classify_stream_type(url),
                'priority': self.calculate_priority(url),
                'verified': 'real'
            }
            stream_list.append(stream_data)

        # ğŸ“ˆ ORDENAR POR PRIORIDAD
        stream_list.sort(key=lambda x: x['priority'], reverse=True)

        # ğŸ“Š ACTUALIZAR ESTADÃSTICAS
        with self.lock:
            self.stats['streams_found'] += len(stream_list)

        logger.info(f"âœ… Encontrados {len(stream_list)} streams REALES para {event_name[:30]}")
        return stream_list

    def normalize_url(self, url, base_url):
        """NormalizaciÃ³n de URL"""
        if not url or not isinstance(url, str):
            return None
        
        url = url.strip().replace('\\', '').replace('\n', '').replace('\r', '')
        
        if url.startswith(('http://', 'https://')):
            return url
        elif url.startswith('//'):
            return 'https:' + url
        elif url.startswith('/'):
            parsed_base = urlparse(base_url)
            return f'{parsed_base.scheme}://{parsed_base.netloc}{url}'
        else:
            return urljoin(base_url, url)

    def is_real_stream_url(self, url):
        """âœ… VALIDACIÃ“N ESTRICTA PARA URLS REALES ÃšNICAMENTE"""
        if not url or not isinstance(url, str) or len(url) < 20:
            return False
        
        url_lower = url.lower()
        
        # âœ… SOLO ACEPTAR PATRONES REALES VERIFICADOS
        real_patterns = [
            r'webplayer2?\.php\?.*t=(?:youtube|alieztv|ifr)',
            r'export/webplayer\.iframe\.php\?',
            r'gowm\.php\?.*eid=\d+',
            r'livetv\d*\.(?:sx|me).*webplayer',
            # AÃ±adir mÃ¡s patrones SOLO si son verificados como reales
        ]
        
        # âŒ RECHAZAR PATRONES SINTÃ‰TICOS O FALSOS
        fake_patterns = [
            r'cdn\.livetv\d+\.me',  # Estos parecen ser sintÃ©ticos
            r'voodc\.com',          # Verificar si es real
            r'\.(js|css|png|jpg|jpeg|gif|ico|svg|woff|pdf|doc)(\?|$)',
            r'/(share|cookie|privacy|terms|about|contact|help|register|login)(\?|$)',
        ]
        
        # Verificar que NO sea falso
        for fake_pattern in fake_patterns:
            if re.search(fake_pattern, url_lower):
                with self.lock:
                    self.stats['fake_iframes_skipped'] += 1
                return False
        
        # Verificar que SÃ sea real
        for real_pattern in real_patterns:
            if re.search(real_pattern, url_lower):
                return True
        
        return False

    def classify_stream_type(self, url):
        """ClasificaciÃ³n del tipo de stream"""
        if not url:
            return 'unknown'
        
        url_lower = url.lower()
        
        if 't=youtube' in url_lower:
            return 'youtube'
        elif 't=alieztv' in url_lower:
            return 'aliez'
        elif 't=ifr' in url_lower:
            return 'iframe'
        elif 'webplayer2' in url_lower:
            return 'webplayer2'
        elif 'webplayer' in url_lower:
            return 'webplayer'
        elif 'gowm.php' in url_lower:
            return 'gowm'
        else:
            return 'generic'

    def calculate_priority(self, url):
        """CÃ¡lculo de prioridad del stream"""
        if not url:
            return 0
        
        priority = 0
        url_lower = url.lower()
        
        # ğŸ† PRIORIDAD POR TIPO VERIFICADO
        if 't=youtube' in url_lower:
            priority += 10
        elif 't=alieztv' in url_lower:
            priority += 8
        elif 't=ifr' in url_lower:
            priority += 6
        
        if 'webplayer2.php' in url_lower:
            priority += 5
        elif 'webplayer.php' in url_lower:
            priority += 4
        
        # ğŸ“‹ BONIFICACIÃ“N POR PARÃMETROS COMPLETOS
        if all(param in url for param in ['eid=', 'lang=', 'c=']):
            priority += 3
        
        return priority

    def generate_xml(self, events, output_file='eventos_livetv_sx_con_reproductores.xml'):
        """ğŸ“„ GENERACIÃ“N DE XML CON NOMBRE CORRECTO"""
        logger.info(f"ğŸ“„ Generando XML: {output_file}")
        
        root = ET.Element('eventos')
        root.set('generado', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        root.set('total', str(len(events)))
        root.set('fecha_filtro', self.current_date_spain)
        root.set('version', '5.0-real-only')
        root.set('extractor', 'LiveTVRealStreamExtractor')
        
        total_streams = 0
        
        for event in events:
            evento_elem = ET.SubElement(root, 'evento')
            evento_elem.set('id', str(event.get('id', 'unknown')))
            
            # ğŸ“‹ CAMPOS BÃSICOS DEL EVENTO
            basic_fields = ['nombre', 'deporte', 'competicion', 'fecha', 'hora', 'url', 'datetime_iso', 'cerca_hora_actual']
            for field in basic_fields:
                if field in event:
                    elem = ET.SubElement(evento_elem, field)
                    elem.text = str(event[field])
            
            # ğŸ¥ ELEMENTO STREAMS
            streams_elem = ET.SubElement(evento_elem, 'streams')
            event_streams = event.get('streams', [])
            streams_elem.set('total', str(len(event_streams)))
            streams_elem.set('solo_reales', 'true')
            
            for i, stream in enumerate(event_streams, 1):
                stream_elem = ET.SubElement(streams_elem, 'stream')
                stream_elem.set('index', str(i))
                stream_elem.set('type', stream.get('type', 'unknown'))
                stream_elem.set('priority', str(stream.get('priority', 0)))
                stream_elem.set('verified', stream.get('verified', 'unknown'))
                
                url_elem = ET.SubElement(stream_elem, 'url')
                url_elem.text = str(stream['url'])
            
            total_streams += len(event_streams)
        
        # ğŸ“Š ESTADÃSTICAS
        stats_elem = ET.SubElement(root, 'estadisticas')
        stats_elem.set('eventos_procesados', str(self.stats['events_processed']))
        stats_elem.set('streams_totales', str(total_streams))
        stats_elem.set('iframes_reales', str(self.stats['real_iframes_found']))
        stats_elem.set('iframes_falsos_omitidos', str(self.stats['fake_iframes_skipped']))
        stats_elem.set('promedio_streams', str(round(total_streams / len(events), 2) if events else '0'))
        stats_elem.set('eventos_fallidos', str(self.stats['failed_events']))
        
        # ğŸ’¾ GUARDAR XML
        tree = ET.ElementTree(root)
        try:
            ET.indent(tree, space="  ", level=0)
            tree.write(output_file, encoding='utf-8', xml_declaration=True)
            
            file_size = Path(output_file).stat().st_size
            logger.info(f"âœ… XML generado: {output_file} ({file_size} bytes)")
            return output_file
            
        except Exception as e:
            logger.error(f"âŒ Error al generar XML: {e}")
            return None

    def run_extraction(self, max_workers=2, time_limit=900):
        """ğŸš€ EJECUTAR EXTRACCIÃ“N DE STREAMS REALES"""
        logger.info("=" * 80)
        logger.info("ğŸš€ EXTRACTOR DE STREAMS REALES LIVETV.SX - VERSIÃ“N 5.0")
        logger.info(f"ğŸ“… Solo eventos del dÃ­a actual EspaÃ±a: {self.current_date_spain}")
        logger.info("ğŸ¯ Solo iframes REALES verificados - SIN contenido sintÃ©tico")
        logger.info("=" * 80)
        
        start_time = time.time()
        
        # ğŸ“‹ CARGAR EVENTOS
        events = self.load_reference_events()
        if not events:
            logger.error("âŒ No se encontraron eventos para hoy")
            return None
        
        logger.info(f"ğŸ“Š Procesando {len(events)} eventos de hoy")
        
        # ğŸ”„ PROCESAR EVENTOS
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_event = {
                executor.submit(
                    self.extract_real_streams_only, 
                    event['url'], 
                    event.get('nombre', 'Sin nombre')
                ): event for event in events
            }
            
            for i, future in enumerate(concurrent.futures.as_completed(future_to_event), 1):
                event = future_to_event[future]
                
                # â° VERIFICAR LÃMITE DE TIEMPO
                elapsed_time = time.time() - start_time
                if elapsed_time > time_limit:
                    logger.warning(f"â° LÃ­mite de tiempo ({time_limit}s) alcanzado")
                    break
                
                try:
                    event['streams'] = future.result()
                    with self.lock:
                        self.stats['events_processed'] += 1
                    
                    streams_count = len(event['streams'])
                    progress = f"[{i}/{len(events)}]"
                    event_name = event.get('nombre', 'Sin nombre')[:40]
                    
                    logger.info(f"âœ… {progress} {event_name}: {streams_count} streams reales")
                    
                except Exception as e:
                    logger.error(f"âŒ Error: {event.get('nombre', 'Sin nombre')[:40]}: {str(e)[:100]}")
                    event['streams'] = []
                    with self.lock:
                        self.stats['failed_events'] += 1
                
                # ğŸ˜´ DELAY CORTO
                time.sleep(random.uniform(0.5, 1.0))
        
        # ğŸ“„ GENERAR XML CON NOMBRE CORRECTO
        xml_file = self.generate_xml(events)
        
        if xml_file:
            execution_time = time.time() - start_time
            avg_streams = self.stats['streams_found'] / self.stats['events_processed'] if self.stats['events_processed'] else 0
            
            logger.info("=" * 80)
            logger.info("ğŸ‰ Â¡EXTRACCIÃ“N EXITOSA!")
            logger.info("=" * 80)
            logger.info(f"â° Tiempo: {execution_time:.2f}s")
            logger.info(f"ğŸ“Š Eventos procesados: {self.stats['events_processed']}")
            logger.info(f"ğŸ¥ Streams reales encontrados: {self.stats['streams_found']}")
            logger.info(f"âœ… iFrames reales: {self.stats['real_iframes_found']}")
            logger.info(f"âŒ iFrames falsos omitidos: {self.stats['fake_iframes_skipped']}")
            logger.info(f"ğŸ“ˆ Promedio streams/evento: {avg_streams:.1f}")
            logger.info(f"ğŸ“„ Archivo: {xml_file}")
            logger.info("=" * 80)
            
            return xml_file
        
        logger.error("âŒ Error al generar el XML final")
        return None

def main():
    """ğŸ¬ FUNCIÃ“N PRINCIPAL"""
    print("=" * 100)
    print("ğŸš€ EXTRACTOR DE STREAMS REALES LIVETV.SX - VERSIÃ“N 5.0 ğŸš€")
    print("ğŸ¯ SOLO iFrames REALES - SIN Contenido SintÃ©tico")
    print("ğŸ“… DetecciÃ³n AutomÃ¡tica del DÃ­a Actual (Horario EspaÃ±a)")
    print("ğŸ“„ Genera: eventos_livetv_sx_con_reproductores.xml")
    print("=" * 100)
    
    # ğŸ› ï¸ CREAR EXTRACTOR
    extractor = LiveTVRealStreamExtractor()
    
    # âš™ï¸ CONFIGURACIÃ“N CONSERVADORA
    config = {
        'max_workers': 2,      # Reducido para evitar bloqueos
        'time_limit': 900      # 15 minutos
    }
    
    logger.info(f"âš™ï¸ ConfiguraciÃ³n: {config}")
    logger.info(f"ğŸ‡ªğŸ‡¸ Procesando eventos de: {extractor.current_date_spain}")
    
    # ğŸš€ EJECUTAR EXTRACCIÃ“N
    result = extractor.run_extraction(**config)
    
    if result:
        avg_streams = extractor.stats['streams_found'] / extractor.stats['events_processed'] if extractor.stats['events_processed'] else 0
        
        print(f"""
ğŸ‰ Â¡EXTRACCIÃ“N COMPLETADA EXITOSAMENTE!

ğŸ“„ Archivo generado: {result}
ğŸ“Š EstadÃ­sticas:
   â€¢ Fecha procesada: {extractor.current_date_spain}
   â€¢ Eventos procesados: {extractor.stats['events_processed']}
   â€¢ Streams reales totales: {extractor.stats['streams_found']}
   â€¢ iFrames reales encontrados: {extractor.stats['real_iframes_found']}
   â€¢ iFrames falsos omitidos: {extractor.stats['fake_iframes_skipped']}
   â€¢ Eventos fallidos: {extractor.stats['failed_events']}
   â€¢ Promedio streams/evento: {avg_streams:.1f}

ğŸ” Este script SOLO extrae:
   âœ… iFrames reales verificados de LiveTV.sx
   âœ… Enlaces webplayer.php y webplayer2.php legÃ­timos
   âœ… URLs con parÃ¡metros t=youtube/alieztv/ifr verificados
   âŒ NO genera contenido sintÃ©tico o fake
   
ğŸ“… Siempre procesa el dÃ­a actual en horario de EspaÃ±a
        """)
    else:
        print("\nâŒ Error en la extracciÃ³n. Revisa los logs para mÃ¡s detalles.")
    
    print("=" * 100)

if __name__ == "__main__":
    main()

# ====================================================================
# ğŸ¯ CARACTERÃSTICAS PRINCIPALES DE LA VERSIÃ“N 5.0:
# ====================================================================
# 
# ğŸ“… DETECCIÃ“N AUTOMÃTICA:
#   â€¢ Detecta automÃ¡ticamente el dÃ­a actual en horario de EspaÃ±a
#   â€¢ No requiere configuraciÃ³n manual de fechas
#   â€¢ Usa timezone Europe/Madrid para precisiÃ³n
#
# ğŸ¯ SOLO STREAMS REALES:
#   â€¢ Patrones basados en anÃ¡lisis real de LiveTV.sx
#   â€¢ NO genera contenido sintÃ©tico o fake
#   â€¢ Filtra y omite URLs falsas o sintÃ©ticas
#   â€¢ Solo webplayer.php/webplayer2.php verificados
#
# ğŸ“„ ARCHIVO CORRECTO:
#   â€¢ Genera eventos_livetv_sx_con_reproductores.xml
#   â€¢ Compatible con GitHub Actions
#   â€¢ Metadatos enriquecidos y estadÃ­sticas detalladas
#
# ğŸ”§ OPTIMIZADO:
#   â€¢ ConfiguraciÃ³n conservadora para evitar bloqueos
#   â€¢ Headers dinÃ¡micos anti-detecciÃ³n
#   â€¢ Manejo robusto de errores
#   â€¢ Logging detallado
#
# ====================================================================
