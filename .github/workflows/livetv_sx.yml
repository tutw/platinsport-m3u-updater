# .github/workflows/scrape-livetv.yml

name: Scrape LiveTV.sx Events

on:
  schedule:
    - cron: '0 */1 * * *' 
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-commit:
    runs-on: ubuntu-latest

    env:
      PLAYWRIGHT_BROWSERS_PATH: ${{ github.workspace }}/ms-playwright-browsers 

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          echo "Installing Python dependencies..."
          python -m pip install --upgrade pip
          # Añade playwright-stealth aquí
          pip install requests beautifulsoup4 lxml playwright playwright-stealth 
          playwright install-deps
          playwright install 
          echo "Dependencies installed."

      - name: Run scraping script
        run: |
          echo "Running scraping script..."
          python script_lista_livetv_sx.py
          echo "Scraping script finished."

      - name: Save Playwright debug HTML as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-debug-html
          path: debug_playwright_html_*.html
          retention-days: 5

      - name: Commit and push if XML changed
        run: |
          echo "Checking for changes and committing..."
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add ${{ env.XML_FILENAME }}
          
          if git diff --staged --quiet; then
            echo "No changes to commit in ${{ env.XML_FILENAME }}."
          else
            git commit -m "Automated update of event URLs in ${{ env.XML_FILENAME }}"
            git push
            echo "${{ env.XML_FILENAME }} updated and pushed."
          fi
        env:
          XML_FILENAME: eventos_livetv_sx.xml
